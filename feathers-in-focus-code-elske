{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14010757,"sourceType":"datasetVersion","datasetId":8924522}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk(\"/kaggle/input/feathers-in-focus-model/\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Data preparation**\n\nCreating a dataset that is compatible with torch.DataLoader","metadata":{}},{"cell_type":"code","source":"# importing packages\n\nimport numpy as np\nimport pandas as pd\nimport torch as tc\n\nfrom pathlib import Path\nfrom PIL import Image\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import v2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Transforming images to make them compatible for CNN","metadata":{}},{"cell_type":"code","source":"TRANSFORM_DEFAULT = v2.Compose([\n    v2.ToImage(),\n    v2.Resize((224, 224)),\n    v2.ToDtype(tc.float32, scale=True), \n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_DIR  = Path(\"/kaggle/input/feathers-in-focus-model/aml-2025-feathers-in-focus\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/feathers-in-focus-model//aml-2025-feathers-in-focus/train_images.csv\")\nprint(train_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Defining the type and config parameters of the data","metadata":{}},{"cell_type":"code","source":"# idx, image, label, path\n\nItemType = tuple[int, tc.Tensor, int, str]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define how to read a sample given the index","metadata":{}},{"cell_type":"code","source":"class ImageClassification(Dataset[ItemType]):\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        search_root: Path,\n        transform: v2.Transform = TRANSFORM_DEFAULT,\n    ):\n        self.df = df.reset_index(drop=True)\n        self.search_root = search_root\n        self.transform = transform\n    \n    def __len__(self) -> int:\n        return len(self.df)\n    \n    def _find_image_path(self, filename: str) -> Path:\n        path = self.search_root / filename.lstrip('/')\n        if not path.exists():\n            raise FileNotFoundError(f\"Image file '{filename}' not found at {path}\")\n        return path\n    \n    def __getitem__(self, idx: int) -> ItemType:\n        row = self.df.iloc[idx]\n        \n        filename = Path(str(row[\"image_path\"])).name\n        \n        path = self._find_image_path(filename)\n        \n        image = Image.open(path).convert(\"RGB\")\n        image = self.transform(image)\n        \n        label = int(row[\"label\"])\n        \n        return idx, image, label, str(path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check if set-up works","metadata":{}},{"cell_type":"code","source":"SEARCH_ROOT = Path(\"/kaggle/input/feathers-in-focus-model/aml-2025-feathers-in-focus/train_images\")\n\ntrain_dataset = ImageClassification(\n    df=train_df,\n    search_root=SEARCH_ROOT,\n    transform=TRANSFORM_DEFAULT,\n)\n\nidx0, img0, label0, path0 = train_dataset[0]\nprint(\"Pad eerste image:\", path0)\nprint(\"Image shape:\", img0.shape)\nprint(\"Label:\", label0)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}